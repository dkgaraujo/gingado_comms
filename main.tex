\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{minted}
\usepackage[
backend=biber,
style=authoryear,
]{biblatex}
\usepackage[svgnames]{xcolor}
\usepackage{listings}

\addbibresource{gingado.bib}

\DeclareUnicodeCharacter{0301}{*************************************}

\title{\texttt{gingado}: a machine learning library focused on economics and finance}
\author{Douglas K. G. Araujo\footnote{Economist, Bank for International Settlements. douglas.araujo@bis.org. The views expressed in this paper are those of the author and do not necessarily represent the views of the Bank for International Settlements. The author is thankful to Rodrigo Coelho, Ryan Defina, Emanuel Kohlscheen, Jermy Prenio, Bruno Sabóia and participants at the Irving Fisher Committee-Banca D'Italia workshop "Data science in central banking - Part 2: Data Science in Central Banking: Applications and tools" in February 2022 and at the Royal Statistical Society Finance and Economics Special Interest Group talk in May 2022. All errors and omissions are attributable to the author.}}
\date{This version: 16 June 2022\\First version: 8 February 2022.}

\begin{document}

\maketitle

\section{Introduction}



Conceptually, every machine learning (ML) application entails the combination of a specific dataset, algorithm, cost function and optimisation procedure - and each of these components can be replaced more or less independently from the others (\cite{DeepLearning}). The set of possibilities is particularly wide in many economics and finance use cases (\cite{doi:10.1146/annurev-economics-080217-053433}, \cite{10.1257/jep.31.2.87}, \cite{varian2014big}, \cite{doerr2021big} \cite{chakraborty2017machine}). And there is often no definite answer as to which alternative is best (\cite{10.1257/jep.31.2.87}). Hence, in practice creating a ML application can amount to a fairly artisanal process that requires multiple iterations and attempted improvements until a result considered to be satisfactory is achieved. In fact, as of writing this paper different steps of the process of creating ML models in economics and finance could be more streamlined, ranging from selection and use of the dataset, comparison of different ML models, and crucially, also the model's documentation. 

\texttt{gingado} is a free, open source library that seeks to facilitate the use of ML in economics and finance, while promoting good modelling practices.\footnote{\texttt{gingado}'s instructions, documentation, interactive notebooks and source code are available at \url{https://dkgaraujo.github.io/gingado/}.} It offers three main contributions. First, \texttt{gingado} facilitates data augmentation of the original user dataset with statistical series from official sources, in a way that is relevant for each case and testable on its ability to improve the model's performance. Second, \texttt{gingado} provides automatic benchmark models that perform well on a broad set of situations and that can train quickly to achieve a reasonable if not the best performance for the dataset at hand; users can also make use of a generic benchmark object to create their own automatic benchmarks. And third, \texttt{gingado} promotes documentation of the ML model as part of the development work flow, automatising some documentation steps to leave users room for concentrating on more value-added documentation items such as ethical considerations. Also here \texttt{gingado} offers users the possibility to create their own model documentation templates that are easy to embed in the modelling practice.

Development of the \texttt{gingado} library follows three design principles:
\begin{enumerate}
    \item \textbf{Flexibility}: users can use \texttt{gingado} out of the box or use it to build custom processes and objects that are more suitable for their use cases;
    \item \textbf{Compatibility}: \texttt{gingado} works well with other widely used libraries in data science and machine learning; and
    \item \textbf{Responsibility}: model documentation and ethical considerations are considered key steps in the modelling process and should be facilitated.
\end{enumerate}
In addition, \texttt{gingado} seeks to be a parsimonious library that complements, rather than redoes, existing functionalities of other widely used libraries. \texttt{gingado}'s application programming interface (API) is compatible in particular with \texttt{scikit-learn} (\cite{scikit-learn}) and it can generally be made compatible with other Python machine learning libraries with minimal adjustment. Also, it can be used in a modular way: users might prefer to just augment their datasets; create automatic benchmark models; or document their models.

These characteristics make \texttt{gingado} a useful tool across many domains in economics and finance. Machine learning algorithms are already amply used in economics for prediction problems (in the sense of \cite{PredictionProblems}), causal inference\footnote{A recent compilation of causal inference techniques from various domains is \url{https://neurips.cc/virtual/2021/workshop/21871}.} (\cite{chernozhukov2018generic} for example in randomised experiments), model estimation (\cite{maliar2021deep}, \cite{fernandez2019financial}, \cite{duarte2018machine}), estimation of models with non-traditional data (\cite{ferreira2021forecasting}) and even being the subject of study themselves (\cite{predunequal}, \cite{giannone2021illusion}). \texttt{gingado}'s functionalities can be used as appropriate in each instance.

To showcase practical applications, the online documentation includes one end-to-end example: the automatic benchmark and model documentation functionalities are illustrated with \cite{BARRO19941}'s cross-country dataset with over 60 variables used to analyse drivers of GDP growth per capita.\footnote{Available at: \url{https://dkgaraujo.github.io/gingado/BarroLee1994.html}. Other examples will be added over time.} The example illustrates one way in which \texttt{gingado} can help economists' workflow. The dataset was also recently used by \cite{giannone2021illusion} to study the different predictive abilities of sparse vs dense models.

The next section describes how \texttt{gingado} facilitates data augmentation. Section \ref{bench} outlines the automatic benchmark process, and section \ref{doc} describes \texttt{gingado}'s model documentation framework. The last section concludes. The online documentation describes how to install the most up-to-date version of \texttt{gingado} and also more advanced topics like how to create customised automatic benchmark models and model documentation templates.

\section{Data augmentation} \label{data_augm}
Publicly available data have a long tradition in economics and finance research and practice. For example, the Federal Reserve Bank of St. Louis' Federal Reserve Economic Data (FRED)\footnote{Available at: \url{https://fred.stlouisfed.org}.} system has developed in tandem with the internet itself (see \cite{RePEc:fip:fedlrv:00023} for an interesting narrative of FRED's history). Similarly, numerous other central banks and statistical agencies, as well as the international financial institutions, put datasets in the public domain in one form or the other. A number of statistics organisations created in the early 2000's an initiative to promote the collection, compilation and dissemination of statistical data, the Statistical Data and Metadata Exchange (SDMX), which is now in its version 3.0.\footnote{Available at: \url{https://sdmx.org}. A technical description of version 3.0 is found here: \url{https://sdmx.org/wp-content/uploads/SDMX_3-0-0_SECTION_1_FINAL-1_0.pdf}.} In addition, other data aggregators such as DBnomics\footnote{Available at: \url{https://db.nomics.world}} host an incredible amount of economic and financial series. 

Many of these services allow users to access data in a programmatic way, ie setting up a computer programme to download the data instead of the user manually accessing the website, selecting the data, downloading it in a file and incorporating the data in the analyses. Thanks to SDMX and to the broader availability of user-friendly data application programming interfaces (APIs) like the one offered by FRED, querying data from trusted sources to augment the user's original dataset has become much easier than in the past. Accessing data programmatically also allows any numeric transformations, consistency checks and data imputation routines that are applied on the dataset to be done in a reproducible and transparent way.

In addition, programmatic access to data can also ensure that any newly added datasets are consistent with each other. For example, SDMX includes the concept of "codelists", which are standardised definitions that apply across dataset domains. For example, one specific codelist contains all possible realisations of the frequency of a dataset (ie, daily, weekly, monthly, ...), and another codelist encompasses all possible codes for specific currencies. This technology ensures that the user has greater control over the datasets to be incorporated.

The considerations above are more important hold when models are in the production stage. In economics and finance, ML models are occasionally designed to be run in production settings instead of a one-off execution; and this is often performed by users that were not involved during development and therefore are oblivious to the model's internal functioning. For example, a model forecasting stock prices will be used extensively over time - and by stock traders or portfolio managers, not the developers. These situations tend to take place in situations where the ML model will require future observations of the datasets used for training. Therefore, automating the process of data augmentation in a way that can ensure consistency between datasets helps to insulate users from worrying about these processes related to the use of additional data.

\texttt{gingado} aims to facilitate this process of finding and adding new datasets, leveraging the public availability of reliable data from official sources and automatically ensuring that the augmented dataset is consistent with the original, having the same frequency and time period. With this, when the model is run in the future, potentially by other people or automatically by systems, the same publicly available dataset(s) used during model training are downloaded and used each time with the appropriate time period. The current version of \texttt{gingado} achieves this with by means of its data augmentation object \texttt{AugmentSDMX}; the idea is to gradually add to the public codebase other "data augmenters" that can scan and download publicly available datasets in a way that is consistent with the original dataset.

\subsection{Basic data augmentation process}

Similar to other parts of \texttt{gingado}, the API for data augmentation is designed for compatibility with \texttt{scikit-learn}. Specifically, the user decides which specific sources and dataflows will be scanned for data upon instantiation of the data augmenter object. So far, the object does not perform any activity other than store this and other parameters. It is only when one of the methods \texttt{fit}, \texttt{transform}, or \texttt{fit\_transform} are called that the data augmenter will (a) read characteristics of the data and (b) look in the named sources and dataflows what would be adequate datasets corresponding to the same frequency and time period. This process is shown in listing \ref{AugmentSDMXAPI}, where the data augmenter will look for the European Central Bank's Composite indicator of systemic stress (CISS) and the Bank for International Settlement's dataflow on central bank policy rates.


\begin{listing}[h]
\begin{minted}[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
%bgcolor=LightGray,
fontsize=\footnotesize,
linenos
]{python}
from gingado.augmentation import AugmentSDMX

src = {'ECB': ['CISS'], 'BIS': ['WS_CBPOL_D']}
AugmentSDMX(sources=src).fit_transform(X_train)
\end{minted} 
\caption{Basic example of the \texttt{AugmentSDMX} API}
\label{AugmentSDMXAPI}
\end{listing}

The process described above will result in a dataset that contains the original data, but is now augmented by potentially numerous other series. The data is indexed by time, and for this reason every combination of permissible codelists in the augmented dataset will create a different variable (ie, a different column). For example, even if the original dataset represents only data from Brazil, the augmentation process shown in \ref{AugmentSDMXAPI} will append the CISS for every country in the list as a different column, as well as the central bank policy rates. \texttt{gingado} makes an explicit choice to allow for this, instead of filtering by individual (in this example, retrieving only the dataset about Brazil), because the newly added data can have some level of information on the target variable, and if that is the case the model would probably uncover it. 

\subsection{Data augmentation with SDMX}\label{AugmSDMX}

\texttt{gingado} explores and fetches available datasets from official sources to augment user data using SDMX, an initiative by international organisations (Bank for International Settlements - BIS, European Central Bank - ECB, Organisation for Economic Cooperation and Development - OECD, International Monetary Fund - IMF, World Bank - WB, Eurostat, and United Nations- UN) that develop and publish statistics from these sources. Since its inception in 2001, SDMX has grown to be used by other sources as well - primarily central banks and statistics agencies - as a standard to disseminate their data.

Downloading data from SDMX sources can be advantageous to users because of the variety of sources and the consistency of the concepts describing the datasets. Instead of dealing with the specific data descriptions and download processes of each of the SDMX participant institutions, the user can rely on an API based on standardised concepts to fetch the data. For example, using SDMX to look across multiple sources for data of quarterly frequency related to the countries of Argentina, Brazil and South Africa for the period spanning the first quarter of 2015 to the fourth quarter of 2021 would use the codelists (introduced above) for frequency and for reference area. These are the same across the SDMX sources and dataflows, which facilitates the process of finding relevant datasets.

\texttt{AugmentSDMX} is based on the \texttt{pandasdmx} python package. The backend code searches all listed SDMX sources in this package, and retrieves the dataflows for those it is able to get (some sources may timeout). Given that downloading all the relevant data from all sources could be an expensive operation, users define the SDMX source(s) from which to get the data, as well as the specific dataflows if they wish.

As of the time of writing, the data providers available for automatic download of data using \texttt{AugmentSDMX} are:\footnote{Users can get the up-to-date list with the \texttt{gingado} method \texttt{list\_SDMX\_sources} in \texttt{gingado.utils}.}
\begin{itemize}
    \item Australian Bureau of Statistics
    \item Bundesbank
    \item Bank for International Settlements
    \item Countdown 2030
    \item European Central Bank
    \item Eurostat
    \item International Labour Organization
    \item Internationa Monetary Fund
    \item National Institute of Statistics and Geography (Mexico)
    \item National Institute of Statistics and Economic Studies (France)
    \item National Institute of Statistics (Italy)
    \item National Institute of Statistics (Lithuania)
    \item Norges Bank (Norway)
    \item National Bank of Belgium
    \item Organisation for Economic Cooperation and Development
    \item Pacific Data Hub
    \item Statistics Estonia
    \item United Nations Statistics Division
    \item UN International Children’s Emergency Fund (UNICEF)
    \item World Bank Group’s “World Integrated Trade Solution”
    \item World Bank Group’s “World Development Indicators”
\end{itemize}

Each of those sources offers a number of dataflows, which are closely related datasets. For example, one dataflow related to foreign exchange rates could include the time series of multiple individual exchange rate pairs, and each pair can be downloaded in their nominal or real exchange rate. The dataflows from all of these sources could be available to train the ML model at hand. In total, the sources listed above result in 9,110 dataflows.

One potential drawback of the process is that the computation time might increase as the number of SDMX series are added. This is an important consideration to have, as production version models will also need to incorporate this data - depending on how expensive these transactions are, it could affect. However, for cases where immediate response is not required, the quantity of data could be considered reasonable.

\subsection{Data augmentation with other datasets}

There are many other official agencies that offer freely (and easily) accessible datasets that would certainly be useful to the proposed data augmentation. For example, the Federal Reserve Bank of St Louis maintains the Federal Reserve Economic Data (FRED)\footnote{\url{https://fred.stlouisfed.org}} and related APIs, and the Brazilian Institute for Geography and Statistics (IBGE) has a range of APIs\footnote{\url{https://servicodados.ibge.gov.br/api/docs/}} that offer datasets that could be of use. It would be useful to also be able to use these tools programatically.

While \texttt{gingado} doesn't include these sources above off-the-shelf as automatic augmenters, work on the next versions will concentrate on more flexibly adding data augmenters and crucially, offering users the possibility to do the same. The code already allows for that, for the users willing to adjust the class \texttt{AugmentSDMX} but it is not yet an intuitive process.

\subsection{Is it worth adding more and more data?}
While an increasing amount of data can lead to better results by machine learning models, there are situations where users might want to consider limiting the amount of data being fed to a model. Therefore, the answer to this subsection's title will depend on each use case, and \texttt{gingado} can help the user answer it.

\texttt{AugmentSDMX}'s API is compatible with \texttt{scikit-learn} in a specific way that allows it to be included in a \textit{pipeline}. Pipelines are objects that apply on data a specific sequence of transformations, and possibly a final step consisting of an estimator (such as a predictor). These pipelines exist to allow the cross-validation of the sequence of steps as a whole, and to allow for a consistent way to estimate different versions of the same model without losing control of the data pipeline.

What this means in practice is that the user can apply standard parameter search algorithms such as grid search to test whether or not the inclusion of a particular dataset will impact the model, eg by improving its performance, changing the importance of regressors, etc. This process is exemplified in listing \ref{AugmentSDMXSearch}: the user created with a few lines a model that, when fitted, will estimate the model without augmentation (ie, will "pass through" \texttt{AugmentSDMX}) and with augmentation, in this case using all dataflows made available by the BIS. Beyond that, the user can even jointly search a combination of different parameters governing data augmentation, data transformation and model estimation by combining \texttt{AugmentSDMX} with \texttt{scikit-learn}'s \texttt{Pipeline}.

\begin{listing}[h]
\begin{minted}[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
%bgcolor=LightGray,
fontsize=\footnotesize,
linenos
]{python}
from gingado.augmentation import AugmentSDMX
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline

pipeline = Pipeline([
    ('augmentation', AugmentSDMX(sources={'BIS': 'all'})),
    ('forest', RandomForestRegressor())
])

grid = GridSearchCV(
    estimator=pipeline,
    param_grid={
        'augmentation': ['passthrough', AugmentSDMX(sources={'BIS': 'all'})]
    })
\end{minted} 
\caption{Use of \texttt{AugmentSDMX} in a \texttt{scikit-learn} pipeline}
\label{AugmentSDMXSearch}
\end{listing}

\section{Automatic benchmark} \label{bench}

\texttt{gingado} offers users the possibility of automatically developing a benchmark machine learning model fine-tuned for their particular case, in a short time and with no input from the user other than the data (although users can also fine tune all aspects of the benchmark). This is achieved by means of an embedded parameter grid search mechanism that evaluates different versions of the underlying algorithm on the user's data, and selects that one that performs better as the benchmark.

The objective is to help the user during the exploratory phase of the development of a machine learning model. The practice of establishing a baseline model is common in machine learning practice. Without a goalpost, a baseline model that is relatively simple to understand and benchmark against, it can be difficult in practice to realise if one's model is performing well or just improving from a low base. So \texttt{gingado} allows users to quickly create a fully functioning model that can serve as benchmark, as shown in listing \ref{NewBenchmark}.

\begin{listing}[h]
\begin{minted}[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
%bgcolor=LightGray,
fontsize=\footnotesize,
linenos
]{python}
from gingado.benchmark import ClassificationBenchmark

benchmark = ClassificationBenchmark().fit(X_train, y_train)

y_pred = ClassificationBenchmark().predict(X_test)
\end{minted} 
\caption{Creation of an automatic benchmark model}
\label{NewBenchmark}
\end{listing}

The off-the-shelf implementations of this automatic benchmark model are based on random forests (\cite{breiman1996bagging}, \cite{breiman2001random}), one type for regression tasks and another one for classification. Random forests, one of the most widely used machine learning methods according to industry practitioners (\cite{howard2020deep}) present several advantages that make them good candidates for benchmark models. They tend to have a very good out-of-sample fit, and require little data preparation work compared to other machine learning models. Random forests also provides an intuitive way to measure the individual importance of regressors, although they don't lend themselves to interpreting the channels by which the regressors contribute to the prediction (\cite{varian2014big}). These regressor importance measures are the mean reduction in impurity occurring in the trees that use that particular variable. The values are then typically scaled so that the sum of all feature importance measures is always one. Practitioners use this measurement as one possibility for variable selection (\cite{géron2017hands-on}, \cite{kohlscheen2021does}).

Whenever a benchmark model is fitted to the data, the model automatically creates a documentation. In the off-the-shelf implementations, this documentation is done via the \texttt{ModelCard} object, described in more detail in section \ref{doc}. From then on, the model documentation can be accessed - and most importantly, filled out, from that object.

Benchmark models also have a specific method to compare themselves with other candidate models. This allows users to directly compare their own candidate models with the existing benchmark. When this is done, via the module \texttt{compare}, \texttt{gingado} also includes amongst the candidates to be tested an ensemble combination of all the candidates and the current benchmark. The inclusion of this candidate ensembles serves to leverage the advantage that ensemble models have over simpler models (\cite{giannone2021illusion}).

\subsection{Other use cases for a benchmark model}

In addition to serving as a baseline model during the development of machine learning, users can simply retain the automatic benchmark as their production model. Beyond benchmark-specific functionalities, these objects behave also as normal \texttt{scikit-learn} models and therefore can be applied as any normal model would. 

Benchmarks can be used as a test to see what if any regressors differentiate the most between two or more groups, for example to see if one group of samples has out-of-domain data (as proposed by \cite{howard2020deep}). The test proceed as follows: a random forest classifier is trained on the dataset, with group identifiers serving as the target variable. The forest's calculated regressor importance can then uncover what are the variables that differentiate between groups. This test can be generalised to check what regressors, if any, vary substantially between two or more groups. 

\subsection{Custom automatic benchmarks}
In spite of the empirical qualities of random forests, no single algorithm could plausibly cover all potential use cases. For example, random forests could potentially not perform as well as other established algorithms if the economic or financial data at hand contains multimodal data, ie images, videos, texts and other such data. In addition, random forests cannot extrapolate beyond the range of the training data that was fed to it. And there are some empirical settings in which gradient boosting trees are more used than random forests and other machine learning methods (\cite{jrfm15040165}). Similarly, \cite{TabularDeepLearning} show that neural networks can achieve similar, and in some cases better, performance than tree-based methods in some cases. And \cite{taylor2018forecasting} describe Facebook's own tool (now open sourced) for automatic forecasting, without relying on random forests.

So random forests might not be the first choice for all cases, even though they are expected to work well in a wide array of situations. In addition to the off-the-shelf implementations described above, \texttt{gingado} offers two possibilities for users to set up their own benchmark models. The most straightforward one is to simply pass as argument a model object to the benchmark's method \texttt{set\_benchmark}. This will cause the benchmark object to put this new model in place of the previous benchmark. 

The second object involves the creation of a new benchmark object class altogether. \texttt{gingado} ships with a base class, \texttt{ggdBenchmark}, that contains all the necessary features for a benchmarker object. Users that wish to create their own benchmark models can sub-class from \texttt{ggdBenchmark} and implement the desired funcionalities. The user's benchmark will then work in the same way as the original \texttt{gingado} benchmark models. This user-created benchmark can include any algorithm or combination of algorithms, as long as the API is maintained.

\section{Model documentation} \label{doc}

Stakeholders often require some level of documentation of the machine learning models. From simple descriptions of the model to standardised model reports to fully-fledged evaluation of models, \texttt{gingado} provides a way for models to be more easily documented. The basic idea is that a \textit{documentation template} outlines the specific items to be documented, and various methods allow the user to interact with this template. This template can be seen at any time by the user with the method \texttt{show\_template}.A \texttt{gingado} documenter object also specifies which of those items are to be filled in automatically (eg, model description can be parsed from the machine learning algorithm itself), and how exactly this should be done.

After a documenter is instantiated, it can read information from an existing model as well. Listing \ref{ModelCard} demonstrates how straightforward it is to automatically read information from a model, and then see what are the questions from the documentation template that were not answered automatically by the \texttt{ModelCard} object. Note that the model itself is not a \texttt{gingado} object.\footnote{Currently the base documenter \texttt{ggdModelDocumentation}, from which all documenters in this library derive, can read models created using \texttt{gingado, \texttt{scikit-learn} and \texttt{keras}. Support for automatically reading information from models built with other libraries such as \texttt{PyTorch} is under development.}}

\begin{listing}[h]
\begin{minted}[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
%bgcolor=LightGray,
fontsize=\footnotesize,
linenos
]{python}
from gingado.model_documentation import ModelCard
from tensorflow import keras

keras_clf = keras.Sequential()
keras_clf.add(keras.layers.Dense(16, activation='relu', input_shape=(20,)))
keras_clf.add(keras.layers.Dense(8, activation='relu'))
keras_clf.add(keras.layers.Dense(1, activation='sigmoid'))
keras_clf.compile(optimizer='sgd', loss='binary_crossentropy')
keras_clf.fit(X, y, batch_size=10, epochs=10)

model_doc_keras = ModelCard()
model_doc_keras.read_model(keras_clf)
model_doc_keras.open_questions()
\end{minted} 
\caption{Example of \texttt{ModelCard} reading information from an existing neural network model}
\label{ModelCard}
\end{listing}

At any time, the user can view the current state of the document with the method \texttt{show\_json}, and save or read it to file with \texttt{save\_json} and \texttt{read\_json} respectively. Additional information items that were not included automatically are filled with \texttt{fill\_info} (the user can also override automatic entries). And the remaining items from the template that are not yet filled are shown to the user with the method \texttt{open\_questions}. These methods (and others, not shown for brevity) aim to provide the user with a more direct, hands-on approach to documenting the model, compared to a more traditional setting where a separate document (ie, a MS Word file) need to be written and maintained. Hopefully allowing users to document their models from inside their machine learning development environment will help embed the documentation process as another step of the model development. Another advantage of \texttt{gingado}'s approach is that it is much easier to keep the documentation aligned with the current version of the model. This is particularly important in the settings where the user expects to iterate over different specifications until a suitable model is achieved.

The model documentation is stored as a JSON file, a flexible format that is easy for machines to read, and that can quickly be transformed into objects humans can read more easily, too. \texttt{gingado} uses JSON files because they are a common language to serialise this type of structured information that works across platforms (ie, a JSON file works in Windows machines the same way it works in MacOS, Linux or any other system). Users that want to automatically produce documents in other formats (eg, PDF files) can do so by using these JSON files with other libraries of their choice. And in settings where multiple models are developed and in production, JSON files are a more streamlined format to offer information on each model to comparison scripts.

\texttt{gingado} includes a ready-to-use documenter object, \texttt{ModelCard}. This documentation template is based on the work of \cite{ModelCards}, which I believe strikes a good balance between being a general documentatio template while also prompting the user to answer questions about the model that are relevant from a broader stakeholder perspective. Similar to how users can create their own class of benchmark models, \texttt{gingado} enables users to create their own custom documenters, from the base class \texttt{ggdModelDocumentation}. This allows specific documentation templates to be used in a more automatic way, and can be of particular importance in the context of organisations using machine learning, since they might have their own documentation preferences.

\subsection{Ethical issues in economics and finance machine learning models}
One of the reasons why \texttt{gingado} facilitates model documentation is to promote a greater role for ethical considerations as part of the development of machine learning models in economics and finance: if the model documentation becomes part of development workflow and certain parts of the documentation are automated, then users are presumably more likely to consider these issues at development time, not \textit{ex post}.

There seems to be a wide awareness of the implications from biased datasets feeding into complex, black-box machine learning models in economics and finance.\footnote{A related discussion where ethics and fairness in machine learning has made strides but needs more progress is related to explainable artificial intelligence (XAI) (for example, \cite{BARREDOARRIETA202082}).} They are illustrated for example by \cite{jrfm15040165}, who present a practitioner view on using machine learning while seeking to originate loans without bias, and by \cite{doerr2021big}, who describe central banks' concerns with fairness implications from greater use of machine learning. But the ethical implications of ML do not stem just from the datasets used for training. It is likely that similar issues are important in a variety of uses, in varying degrees. For example, while \cite{Parrots} highlight ethical and societal issues stemming from the incredibly large size of datasets used to train large scale language models. 

But \cite{Parrots} also discuss model-related aspects: eg, the environmental impact of the large-size architecture of these models, and the risks originating from the higher (apparent) fluency of these models. \cite{automateMH} and \cite{thomas2022reliance} discuss pitfalls and risks from the metrics chosen during machine learning development. Therefore, promoting opportunities for machine learning developers to think about the ethical implications from the complete model pipeline, from data to application, seems more than warranted. One recent evidence of the real-life impact of machine learning applications might materially impact stakeholder outcomes is studied by \cite{predunequal}, in the context of mortgage lending. 

\section{Conclusion}

\texttt{gingado} is a free, open source machine learning library focused on use cases in economics and finance - in both research and practice. Its compatibility with widely used machine learning frameworks, most notably \texttt{scikit-learn}, allows it to leverage on the wide familiarity with these tools and complement existing user codebases. And its flexible approach simultaneously affords users the ability to advance machine learning model development with few steps, while enabling users to tweak all tools to meet their goals, including adjusting models and their outcomes to better suit econometric use cases when necessary  (\cite{doi:10.1146/annurev-economics-080217-053433}). The toolset provided by \texttt{gingado} was first created for my own use as a practitioner of machine learning in economics, and I expect to continue developing it over time to incorporate funcionalities that can be of most value-added to researchers and practitioners in economics and finance. At the same time, I hope that \texttt{gingado} can contribute to facilitate greater use of machine learning in economic and finance, while promoting good modelling practices including a greater role for model documentation and ethical considerations. The particular areas focused by \texttt{gingado} are data augmentation, automatic benchmark models, and model documentation.

Adding more data to one's dataset can often be cumbersome from an operational perspective, and especially so when multiple sources are involved. This is of course much harder when the machine learning model is used in a production setting, instead of a one-off analysis. \texttt{gingado} addresses this by augmenting the user dataset through an object that fits nicely in standard machine learning pipelines. This also allows the user to test whether or not adding more data actually improves the model (according to any criteria defined by the user). In addition, \texttt{gingado}'s data augmentation method focuses on ensuring that the data provided to users is from trusted sources. When more data augmentation objects are added to the \texttt{gingado} codebase, the reliability of data sources will be a key criterion.

Automatic benchmark models are not new. \cite{fastai} and \cite{taylor2018forecasting} for example enable users to quickly set up models with a reasonably good performance for the vast majority of use cases in their respective domains. \texttt{gingado} builds on that insight and provides users with additional functionalities that to my knowledge are novel. Namely, a way to conveniently compare candidate models (and their ensemble) and pick the best one as the new benchmark, the automatic documentation of the benchmark model, and the ability to create one's own benchmark from a base class aim to push standard practice of how to set up baseline models.

And finally, model documentation. \cite{10.1257/jep.31.2.87} mention the risk that machine learning models in economics and finance be applied naïvely or have their outputs misinterpreted. This risk increases with greater deployment of machine learning in important aspects of daily life, such as banking\footnote{For example, in March 2022 the Basel Committee on Banking Supervision affirmed that "\textit{Banks are increasingly exploring opportunities for using artificial intelligence, including machine learning}" (available at: \url{https://www.bis.org/publ/bcbs_nl27.htm}).}. But the risk probably also grows as the technical preconditions for machine learning, such as greater availability of higher-dimensional datasets and of compute power, facilitate model development by more people. As the popularity of machine learning models amongst economists grow, my goal with \texttt{gingado} is to contribute a small part to embed model documentation in the process of model development, automating some of the questions to afford the humans in control the opportunity to properly document their models and pay due consideration to ethical issues arising in each particular situation.



%\bibliography{gingado.bib}
%\bibliographystyle{science}
\printbibliography
\end{document}
